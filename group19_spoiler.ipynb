{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cfa2dfb-343f-4354-ad7c-205e2c60da5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kangcat/miniconda3/envs/documentation/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/home/kangcat/miniconda3/envs/documentation/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/kangcat/miniconda3/envs/documentation/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/kangcat/miniconda3/envs/documentation/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4368dffe-595e-4391-98c4-19c764c50d0d",
   "metadata": {},
   "source": [
    "### Preparing dataset\n",
    "1. user_id\n",
    "2. review_text\n",
    "3. plot_synopsis\n",
    "4. review_text embeddings\n",
    "5. cosine similarity\n",
    "6. ngram vector\n",
    "7. review text length\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db4cd541-78d6-4c35-ba8d-0dbee7c77403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19f8ee07-5a7e-40f1-9081-e02d78a60be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (573913, 8)\n",
      "Dataset shape: (1572, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_date</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_spoiler</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 February 2006</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur1898687</td>\n",
       "      <td>1</td>\n",
       "      <td>oscar year shawshank redemption write direct f...</td>\n",
       "      <td>10</td>\n",
       "      <td>A classic piece of unforgettable film-making.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6 September 2000</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur0842118</td>\n",
       "      <td>1</td>\n",
       "      <td>shawshank redemption without doubt one brillia...</td>\n",
       "      <td>10</td>\n",
       "      <td>Simply amazing. The best film of the 90's.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 August 2001</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur1285640</td>\n",
       "      <td>1</td>\n",
       "      <td>believe film best story ever tell film tell ti...</td>\n",
       "      <td>8</td>\n",
       "      <td>The best story ever told on film</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 September 2002</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur1003471</td>\n",
       "      <td>1</td>\n",
       "      <td>yes spoiler film emotional impact find hard wr...</td>\n",
       "      <td>10</td>\n",
       "      <td>Busy dying or busy living?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20 May 2004</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur0226855</td>\n",
       "      <td>1</td>\n",
       "      <td>heart extraordinary movie brilliant indelible ...</td>\n",
       "      <td>8</td>\n",
       "      <td>Great story, wondrously told and acted</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        review_date   movie_id    user_id  is_spoiler  \\\n",
       "0  10 February 2006  tt0111161  ur1898687           1   \n",
       "1  6 September 2000  tt0111161  ur0842118           1   \n",
       "2     3 August 2001  tt0111161  ur1285640           1   \n",
       "3  1 September 2002  tt0111161  ur1003471           1   \n",
       "4       20 May 2004  tt0111161  ur0226855           1   \n",
       "\n",
       "                                         review_text  rating  \\\n",
       "0  oscar year shawshank redemption write direct f...      10   \n",
       "1  shawshank redemption without doubt one brillia...      10   \n",
       "2  believe film best story ever tell film tell ti...       8   \n",
       "3  yes spoiler film emotional impact find hard wr...      10   \n",
       "4  heart extraordinary movie brilliant indelible ...       8   \n",
       "\n",
       "                                  review_summary  label  \n",
       "0  A classic piece of unforgettable film-making.      1  \n",
       "1     Simply amazing. The best film of the 90's.      1  \n",
       "2               The best story ever told on film      1  \n",
       "3                     Busy dying or busy living?      1  \n",
       "4         Great story, wondrously told and acted      1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_path = \"/SFS/project/ry/dp_sgteam/catherine/ada/dataset\"\n",
    "df_reviews = pd.read_json(f\"{directory_path}/cleaned_data.json\")\n",
    "df_reviews['label'] = df_reviews['is_spoiler'].astype(int)\n",
    "\n",
    "df_movies = pd.read_json(f\"{directory_path}/IMDB_movie_details.json\", lines=True)\n",
    "\n",
    "print(f\"Dataset shape: {df_reviews.shape}\")\n",
    "print(f\"Dataset shape: {df_movies.shape}\")\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "780bc275-e47c-4d56-b430-f86348570531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and merged successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>label</th>\n",
       "      <th>review_text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1898687</td>\n",
       "      <td>oscar year shawshank redemption write direct f...</td>\n",
       "      <td>In 1947, Andy Dufresne (Tim Robbins), a banker...</td>\n",
       "      <td>1</td>\n",
       "      <td>2776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842118</td>\n",
       "      <td>shawshank redemption without doubt one brillia...</td>\n",
       "      <td>In 1947, Andy Dufresne (Tim Robbins), a banker...</td>\n",
       "      <td>1</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1285640</td>\n",
       "      <td>believe film best story ever tell film tell ti...</td>\n",
       "      <td>In 1947, Andy Dufresne (Tim Robbins), a banker...</td>\n",
       "      <td>1</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003471</td>\n",
       "      <td>yes spoiler film emotional impact find hard wr...</td>\n",
       "      <td>In 1947, Andy Dufresne (Tim Robbins), a banker...</td>\n",
       "      <td>1</td>\n",
       "      <td>2148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>226855</td>\n",
       "      <td>heart extraordinary movie brilliant indelible ...</td>\n",
       "      <td>In 1947, Andy Dufresne (Tim Robbins), a banker...</td>\n",
       "      <td>1</td>\n",
       "      <td>2735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                        review_text  \\\n",
       "0  1898687  oscar year shawshank redemption write direct f...   \n",
       "1   842118  shawshank redemption without doubt one brillia...   \n",
       "2  1285640  believe film best story ever tell film tell ti...   \n",
       "3  1003471  yes spoiler film emotional impact find hard wr...   \n",
       "4   226855  heart extraordinary movie brilliant indelible ...   \n",
       "\n",
       "                                       plot_synopsis  label  \\\n",
       "0  In 1947, Andy Dufresne (Tim Robbins), a banker...      1   \n",
       "1  In 1947, Andy Dufresne (Tim Robbins), a banker...      1   \n",
       "2  In 1947, Andy Dufresne (Tim Robbins), a banker...      1   \n",
       "3  In 1947, Andy Dufresne (Tim Robbins), a banker...      1   \n",
       "4  In 1947, Andy Dufresne (Tim Robbins), a banker...      1   \n",
       "\n",
       "   review_text_length  \n",
       "0                2776  \n",
       "1                 709  \n",
       "2                 962  \n",
       "3                2148  \n",
       "4                2735  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df_reviews, df_movies, on='movie_id', how='left')\n",
    "\n",
    "print(\"Data loaded and merged successfully.\")\n",
    "df['label'] = df['is_spoiler'].astype(int)\n",
    "df['user_id'] = df['user_id'].str[2:].astype(int)\n",
    "\n",
    "df = df[['user_id', 'review_text', 'plot_synopsis', 'label']]\n",
    "df['review_text_length'] = df['review_text'].str.len()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27d2d8f3-4155-4315-a406-c0be2453e222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into train (459130) and test (114783) sets.\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df['label'],\n",
    "    random_state=42\n",
    ")\n",
    "print(f\"Data split into train ({len(train_df)}) and test ({len(test_df)}) sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef2b82d1-17d7-4128-93ce-8f88f6c10b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in (train_df, test_df):\n",
    "    obj.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c731016e-c5ca-4d24-9b33-6b4836b3dede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 500 thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "921ffca7-8451-40af-ac46-5942e38b0bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedd_to_vector(text):\n",
    "    print(\"Encoding texts...\")\n",
    "    embeddings = model.encode(text.fillna('').tolist(), \n",
    "                              convert_to_tensor=True, show_progress_bar=True, device=device)\n",
    "    print(\"Encoded.\")\n",
    "    return embeddings.cpu().numpy().tolist()\n",
    "\n",
    "def concat_to_df(main_df, embedd_list, column_name):\n",
    "    embedd_df = pd.DataFrame(embedd_list)\n",
    "    num_dims = len(embedd_df.columns)\n",
    "    new_names = [f'{column_name}_{i}' for i in range(num_dims)]\n",
    "    embedd_df.columns = new_names\n",
    "    df = pd.concat([main_df, embedd_df], axis = 1)\n",
    "    print(f\"Finish concatenate: with dataframe {len(main_df)} and list {len(embedd_df)}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9fa6fe6-aac3-47f0-b779-75d4d0faf5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████████████████████████████████████████████████| 14348/14348 [02:40<00:00, 89.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded.\n",
      "Encoding texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████████████████████████████████████████████████| 14348/14348 [09:49<00:00, 24.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded.\n",
      "Finish concatenate: with dataframe 459130 and list 459130\n"
     ]
    }
   ],
   "source": [
    "train_review_embeddings = embedd_to_vector(train_df['review_text'])\n",
    "train_synopsis_embeddings = embedd_to_vector(train_df['plot_synopsis'])\n",
    "\n",
    "train_df = concat_to_df(train_df, train_review_embeddings, \"dim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "928daeac-81f7-4746-b548-2d1742854d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|████████████████████████████████████████████████████████| 3587/3587 [00:39<00:00, 89.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded.\n",
      "Encoding texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|████████████████████████████████████████████████████████| 3587/3587 [02:44<00:00, 21.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded.\n",
      "Finish concatenate: with dataframe 114783 and list 114783\n"
     ]
    }
   ],
   "source": [
    "test_review_embeddings = embedd_to_vector(test_df['review_text'])\n",
    "test_synopsis_embeddings = embedd_to_vector(test_df['plot_synopsis'])\n",
    "\n",
    "test_df = concat_to_df(test_df, test_review_embeddings, \"dim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57637316-08c0-4aae-be02-cbe47d18728d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating similarities for training set...\n",
      "Calculating similarities for testing set...\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating similarities for training set...\")\n",
    "sim_scores_train = util.pairwise_cos_sim(train_review_embeddings, train_synopsis_embeddings)\n",
    "train_df['sim_score_synopsis_review'] = sim_scores_train.flatten()\n",
    "\n",
    "print(\"Calculating similarities for testing set...\")\n",
    "sim_scores_test = util.pairwise_cos_sim(test_review_embeddings, test_synopsis_embeddings)\n",
    "test_df['sim_score_synopsis_review'] = sim_scores_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81f566b9-f1cf-4bc4-8262-29994c6de991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-gram\n",
    "with open(\"/SFS/project/ry/dp_sgteam/catherine/ada/dataset/ngram_vocab_list.json\", \"r\") as f:\n",
    "    ngram_vocab_list = json.load(f)\n",
    "\n",
    "ngram_to_idx = {ngram: idx for idx, ngram in enumerate(ngram_vocab_list)}\n",
    "vocab_size = len(ngram_vocab_list)\n",
    "\n",
    "def build_token_set(text):\n",
    "    tokens = re.findall(r\"[A-Za-z]+\", text.lower())\n",
    "    return tokens\n",
    "\n",
    "def ngram_vector_for_text(text, ngram_to_idx, vocab_size):\n",
    "    tokens = build_token_set(text)\n",
    "    token_set = set(tokens)\n",
    "    bigram_set = set(\" \".join(pair) for pair in zip(tokens, tokens[1:]))\n",
    "\n",
    "    vec = [0] * vocab_size\n",
    "    for ng, idx in ngram_to_idx.items():\n",
    "        if \" \" in ng:\n",
    "            if ng in bigram_set:\n",
    "                vec[idx] = 1\n",
    "        else: \n",
    "            if ng in token_set:\n",
    "                vec[idx] = 1\n",
    "    return vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d2b0f5e-097e-4778-9be2-6562f9594bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish concatenate: with dataframe 459130 and list 459130\n",
      "Finish concatenate: with dataframe 114783 and list 114783\n"
     ]
    }
   ],
   "source": [
    "train_ngram_df = pd.DataFrame([ngram_vector_for_text(t, ngram_to_idx, vocab_size) for t in train_df['review_text']])\n",
    "train_df = concat_to_df(train_df, train_ngram_df, \"ngram\")\n",
    "\n",
    "test_ngram_df = pd.DataFrame([ngram_vector_for_text(t, ngram_to_idx, vocab_size) for t in test_df['review_text']])\n",
    "valid_df = concat_to_df(test_df, test_ngram_df, \"ngram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d41fde-a0d5-40a3-987b-bd2d09e41db4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Storing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f882c8c-ef3f-47ce-b817-34b44a6c3e78",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_json\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdirectory_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/train_data.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43morient\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrecords\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m test_df.to_json(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/test_data.json\u001b[39m\u001b[33m\"\u001b[39m,  orient=\u001b[33m\"\u001b[39m\u001b[33mrecords\u001b[39m\u001b[33m\"\u001b[39m, indent=\u001b[32m4\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/documentation/lib/python3.11/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/documentation/lib/python3.11/site-packages/pandas/core/generic.py:2721\u001b[39m, in \u001b[36mNDFrame.to_json\u001b[39m\u001b[34m(self, path_or_buf, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options, mode)\u001b[39m\n\u001b[32m   2718\u001b[39m config.is_nonnegative_int(indent)\n\u001b[32m   2719\u001b[39m indent = indent \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2721\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2723\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2724\u001b[39m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[43m=\u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2725\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdouble_precision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdouble_precision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_ascii\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2728\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdefault_handler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2731\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2734\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2735\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2736\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/documentation/lib/python3.11/site-packages/pandas/io/json/_json.py:210\u001b[39m, in \u001b[36mto_json\u001b[39m\u001b[34m(path_or_buf, obj, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options, mode)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mobj\u001b[39m\u001b[33m'\u001b[39m\u001b[33m should be a Series or a DataFrame\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    200\u001b[39m s = \u001b[43mwriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[43m=\u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdouble_precision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdouble_precision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdefault_handler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lines:\n\u001b[32m    213\u001b[39m     s = convert_to_line_delimits(s)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/documentation/lib/python3.11/site-packages/pandas/io/json/_json.py:263\u001b[39m, in \u001b[36mWriter.write\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    262\u001b[39m     iso_dates = \u001b[38;5;28mself\u001b[39m.date_format == \u001b[33m\"\u001b[39m\u001b[33miso\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mujson_dumps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobj_to_write\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43morient\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdouble_precision\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdouble_precision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43miso_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43miso_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdefault_handler\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_df.to_json(f\"{directory_path}/train_data.json\",  orient=\"records\", indent=4)\n",
    "test_df.to_json(f\"{directory_path}/test_data.json\",  orient=\"records\", indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37e4375-8785-4769-a505-ba9a42ba5029",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07168199-7a67-4f91-a7ff-dfaf995d257c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>label</th>\n",
       "      <th>review_text_length</th>\n",
       "      <th>dim_0</th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>...</th>\n",
       "      <th>ngram_442</th>\n",
       "      <th>ngram_443</th>\n",
       "      <th>ngram_444</th>\n",
       "      <th>ngram_445</th>\n",
       "      <th>ngram_446</th>\n",
       "      <th>ngram_447</th>\n",
       "      <th>ngram_448</th>\n",
       "      <th>ngram_449</th>\n",
       "      <th>ngram_450</th>\n",
       "      <th>ngram_451</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5291991</td>\n",
       "      <td>1</td>\n",
       "      <td>1821</td>\n",
       "      <td>-0.005757</td>\n",
       "      <td>-0.051729</td>\n",
       "      <td>-0.021550</td>\n",
       "      <td>-0.005745</td>\n",
       "      <td>-0.074771</td>\n",
       "      <td>0.078937</td>\n",
       "      <td>-0.069202</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48053412</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>-0.002652</td>\n",
       "      <td>-0.056541</td>\n",
       "      <td>0.058831</td>\n",
       "      <td>-0.003095</td>\n",
       "      <td>0.043479</td>\n",
       "      <td>0.030117</td>\n",
       "      <td>0.054024</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28438054</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>-0.017446</td>\n",
       "      <td>-0.091489</td>\n",
       "      <td>0.014513</td>\n",
       "      <td>-0.028227</td>\n",
       "      <td>-0.026655</td>\n",
       "      <td>0.060746</td>\n",
       "      <td>0.043278</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35553121</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>-0.081114</td>\n",
       "      <td>0.030047</td>\n",
       "      <td>0.042871</td>\n",
       "      <td>0.093194</td>\n",
       "      <td>-0.001539</td>\n",
       "      <td>-0.004182</td>\n",
       "      <td>0.031489</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14069613</td>\n",
       "      <td>0</td>\n",
       "      <td>1333</td>\n",
       "      <td>-0.051064</td>\n",
       "      <td>-0.072159</td>\n",
       "      <td>-0.044826</td>\n",
       "      <td>-0.012800</td>\n",
       "      <td>-0.006169</td>\n",
       "      <td>0.065184</td>\n",
       "      <td>0.030398</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 840 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  label  review_text_length     dim_0     dim_1     dim_2  \\\n",
       "0   5291991      1                1821 -0.005757 -0.051729 -0.021550   \n",
       "1  48053412      1                 829 -0.002652 -0.056541  0.058831   \n",
       "2  28438054      1                 829 -0.017446 -0.091489  0.014513   \n",
       "3  35553121      0                 182 -0.081114  0.030047  0.042871   \n",
       "4  14069613      0                1333 -0.051064 -0.072159 -0.044826   \n",
       "\n",
       "      dim_3     dim_4     dim_5     dim_6  ...  ngram_442  ngram_443  \\\n",
       "0 -0.005745 -0.074771  0.078937 -0.069202  ...          0          0   \n",
       "1 -0.003095  0.043479  0.030117  0.054024  ...          0          0   \n",
       "2 -0.028227 -0.026655  0.060746  0.043278  ...          0          0   \n",
       "3  0.093194 -0.001539 -0.004182  0.031489  ...          0          0   \n",
       "4 -0.012800 -0.006169  0.065184  0.030398  ...          0          0   \n",
       "\n",
       "   ngram_444  ngram_445  ngram_446  ngram_447  ngram_448  ngram_449  \\\n",
       "0          0          0          0          0          0          0   \n",
       "1          0          0          0          0          0          0   \n",
       "2          0          0          0          0          0          0   \n",
       "3          0          0          0          0          0          0   \n",
       "4          0          0          0          0          0          0   \n",
       "\n",
       "   ngram_450  ngram_451  \n",
       "0          0          0  \n",
       "1          0          0  \n",
       "2          0          0  \n",
       "3          0          0  \n",
       "4          0          0  \n",
       "\n",
       "[5 rows x 840 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xg = train_df.drop(columns= ['review_text', 'plot_synopsis'])\n",
    "\n",
    "df_xg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f44da1d-6b46-495c-b534-9a2eb51b5e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7811561100505529\n",
      "Accuracy: 0.7038529392546773\n",
      "F1: 0.5526272496956536\n",
      "ngram_0                      0.087770\n",
      "dim_319                      0.034076\n",
      "review_text_length           0.028817\n",
      "user_id                      0.019276\n",
      "dim_223                      0.011733\n",
      "dim_49                       0.008892\n",
      "dim_187                      0.008151\n",
      "dim_298                      0.006987\n",
      "dim_92                       0.006019\n",
      "sim_score_synopsis_review    0.006016\n",
      "dim_111                      0.005069\n",
      "ngram_10                     0.005048\n",
      "dim_127                      0.004980\n",
      "dim_331                      0.004912\n",
      "ngram_115                    0.004893\n",
      "dim_139                      0.004565\n",
      "ngram_162                    0.004483\n",
      "dim_244                      0.004433\n",
      "ngram_8                      0.004386\n",
      "dim_217                      0.004234\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "X = df_xg.drop(columns=[\"label\"])\n",
    "y = df_xg[\"label\"]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "clf = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    min_child_weight=1,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    "    tree_method=\"gpu_hist\",          # use \"gpu_hist\" if you have a GPU\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    scale_pos_weight = 2.8\n",
    ")\n",
    "\n",
    "clf.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "proba = clf.predict_proba(X_valid)[:, 1]\n",
    "pred = (proba >= 0.5).astype(int)\n",
    "print(\"AUC:\", roc_auc_score(y_valid, proba))\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, pred))\n",
    "print(\"F1:\", f1_score(y_valid, pred))\n",
    "\n",
    "# Feature importance (gain-based)\n",
    "importances = pd.Series(clf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "print(importances.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09c3caf0-b512-49ea-a82a-5e9a41d4983d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Not Spoiler       0.87      0.71      0.78     67678\n",
      "     Spoiler       0.46      0.70      0.55     24148\n",
      "\n",
      "    accuracy                           0.70     91826\n",
      "   macro avg       0.66      0.70      0.67     91826\n",
      "weighted avg       0.76      0.70      0.72     91826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, pred, target_names=['Not Spoiler', 'Spoiler'], zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e588c37-720a-45e7-af2e-0606bd56720f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21465172, 0.08334256, 0.24616382, ..., 0.31994042, 0.00211977,\n",
       "       0.45506656], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00004e0-ce94-4eef-a67e-ec36efaf4f62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch CUDA 11.8)",
   "language": "python",
   "name": "documentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
