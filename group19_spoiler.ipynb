{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cfa2dfb-343f-4354-ad7c-205e2c60da5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kangcat/miniconda3/envs/documentation/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/home/kangcat/miniconda3/envs/documentation/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/kangcat/miniconda3/envs/documentation/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/kangcat/miniconda3/envs/documentation/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db4cd541-78d6-4c35-ba8d-0dbee7c77403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19f8ee07-5a7e-40f1-9081-e02d78a60be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (573913, 8)\n",
      "Dataset shape: (1572, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_date</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_spoiler</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 February 2006</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur1898687</td>\n",
       "      <td>True</td>\n",
       "      <td>In its Oscar year, Shawshank Redemption (writt...</td>\n",
       "      <td>10</td>\n",
       "      <td>A classic piece of unforgettable film-making.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6 September 2000</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur0842118</td>\n",
       "      <td>True</td>\n",
       "      <td>The Shawshank Redemption is without a doubt on...</td>\n",
       "      <td>10</td>\n",
       "      <td>Simply amazing. The best film of the 90's.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 August 2001</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur1285640</td>\n",
       "      <td>True</td>\n",
       "      <td>I believe that this film is the best story eve...</td>\n",
       "      <td>8</td>\n",
       "      <td>The best story ever told on film</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 September 2002</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur1003471</td>\n",
       "      <td>True</td>\n",
       "      <td>**Yes, there are SPOILERS here**This film has ...</td>\n",
       "      <td>10</td>\n",
       "      <td>Busy dying or busy living?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20 May 2004</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur0226855</td>\n",
       "      <td>True</td>\n",
       "      <td>At the heart of this extraordinary movie is a ...</td>\n",
       "      <td>8</td>\n",
       "      <td>Great story, wondrously told and acted</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        review_date   movie_id    user_id  is_spoiler  \\\n",
       "0  10 February 2006  tt0111161  ur1898687        True   \n",
       "1  6 September 2000  tt0111161  ur0842118        True   \n",
       "2     3 August 2001  tt0111161  ur1285640        True   \n",
       "3  1 September 2002  tt0111161  ur1003471        True   \n",
       "4       20 May 2004  tt0111161  ur0226855        True   \n",
       "\n",
       "                                         review_text  rating  \\\n",
       "0  In its Oscar year, Shawshank Redemption (writt...      10   \n",
       "1  The Shawshank Redemption is without a doubt on...      10   \n",
       "2  I believe that this film is the best story eve...       8   \n",
       "3  **Yes, there are SPOILERS here**This film has ...      10   \n",
       "4  At the heart of this extraordinary movie is a ...       8   \n",
       "\n",
       "                                  review_summary  label  \n",
       "0  A classic piece of unforgettable film-making.      1  \n",
       "1     Simply amazing. The best film of the 90's.      1  \n",
       "2               The best story ever told on film      1  \n",
       "3                     Busy dying or busy living?      1  \n",
       "4         Great story, wondrously told and acted      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews = pd.read_json('/SFS/project/ry/dp_sgteam/catherine/ada/dataset/IMDB_reviews.json', lines=True)\n",
    "df_reviews['label'] = df_reviews['is_spoiler'].astype(int)\n",
    "\n",
    "df_movies = pd.read_json('/SFS/project/ry/dp_sgteam/catherine/ada/dataset/IMDB_movie_details.json', lines=True)\n",
    "\n",
    "print(f\"Dataset shape: {df_reviews.shape}\")\n",
    "print(f\"Dataset shape: {df_movies.shape}\")\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "780bc275-e47c-4d56-b430-f86348570531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and merged successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>label</th>\n",
       "      <th>review_text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1898687</td>\n",
       "      <td>In its Oscar year, Shawshank Redemption (writt...</td>\n",
       "      <td>In 1947, Andy Dufresne (Tim Robbins), a banker...</td>\n",
       "      <td>1</td>\n",
       "      <td>4751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842118</td>\n",
       "      <td>The Shawshank Redemption is without a doubt on...</td>\n",
       "      <td>In 1947, Andy Dufresne (Tim Robbins), a banker...</td>\n",
       "      <td>1</td>\n",
       "      <td>1218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1285640</td>\n",
       "      <td>I believe that this film is the best story eve...</td>\n",
       "      <td>In 1947, Andy Dufresne (Tim Robbins), a banker...</td>\n",
       "      <td>1</td>\n",
       "      <td>1470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003471</td>\n",
       "      <td>**Yes, there are SPOILERS here**This film has ...</td>\n",
       "      <td>In 1947, Andy Dufresne (Tim Robbins), a banker...</td>\n",
       "      <td>1</td>\n",
       "      <td>4096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>226855</td>\n",
       "      <td>At the heart of this extraordinary movie is a ...</td>\n",
       "      <td>In 1947, Andy Dufresne (Tim Robbins), a banker...</td>\n",
       "      <td>1</td>\n",
       "      <td>4632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                        review_text  \\\n",
       "0  1898687  In its Oscar year, Shawshank Redemption (writt...   \n",
       "1   842118  The Shawshank Redemption is without a doubt on...   \n",
       "2  1285640  I believe that this film is the best story eve...   \n",
       "3  1003471  **Yes, there are SPOILERS here**This film has ...   \n",
       "4   226855  At the heart of this extraordinary movie is a ...   \n",
       "\n",
       "                                       plot_synopsis  label  \\\n",
       "0  In 1947, Andy Dufresne (Tim Robbins), a banker...      1   \n",
       "1  In 1947, Andy Dufresne (Tim Robbins), a banker...      1   \n",
       "2  In 1947, Andy Dufresne (Tim Robbins), a banker...      1   \n",
       "3  In 1947, Andy Dufresne (Tim Robbins), a banker...      1   \n",
       "4  In 1947, Andy Dufresne (Tim Robbins), a banker...      1   \n",
       "\n",
       "   review_text_length  \n",
       "0                4751  \n",
       "1                1218  \n",
       "2                1470  \n",
       "3                4096  \n",
       "4                4632  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df_reviews, df_movies, on='movie_id', how='left')\n",
    "\n",
    "print(\"Data loaded and merged successfully.\")\n",
    "df['label'] = df['is_spoiler'].astype(int)\n",
    "df['user_id'] = df['user_id'].str[2:].astype(int)\n",
    "\n",
    "df = df[['user_id', 'review_text', 'plot_synopsis', 'label']]\n",
    "df['review_text_length'] = df['review_text'].str.len()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27d2d8f3-4155-4315-a406-c0be2453e222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into train (459130) and test (114783) sets.\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df['label'],\n",
    "    random_state=42\n",
    ")\n",
    "print(f\"Data split into train ({len(train_df)}) and test ({len(test_df)}) sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c8c7b5c-badb-4c2e-a099-40b3cba32361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into train (367304) and valid (91826) sets.\n"
     ]
    }
   ],
   "source": [
    "train_df, valid_df = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.2,\n",
    "    stratify=train_df['label'],\n",
    "    random_state=42\n",
    ")\n",
    "print(f\"Data split into train ({len(train_df)}) and valid ({len(valid_df)}) sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef2b82d1-17d7-4128-93ce-8f88f6c10b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in (train_df, valid_df, test_df):\n",
    "    obj.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c731016e-c5ca-4d24-9b33-6b4836b3dede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 500 thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 500 thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/./modules.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "HTTP Error 500 thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/./modules.json\n",
      "Retrying in 4s [Retry 3/5].\n",
      "HTTP Error 500 thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/./modules.json\n",
      "Retrying in 8s [Retry 4/5].\n",
      "HTTP Error 500 thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/./modules.json\n",
      "Retrying in 8s [Retry 5/5].\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "921ffca7-8451-40af-ac46-5942e38b0bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedd_to_vector(text):\n",
    "    print(\"Encoding texts...\")\n",
    "    embeddings = model.encode(text.fillna('').tolist(), \n",
    "                              convert_to_tensor=True, show_progress_bar=True, device=device)\n",
    "    print(\"Encoded.\")\n",
    "    return embeddings.cpu().numpy().tolist()\n",
    "\n",
    "def concat_to_df(main_df, embedd_list, column_name):\n",
    "    embedd_df = pd.DataFrame(embedd_list)\n",
    "    num_dims = len(embedd_df.columns)\n",
    "    new_names = [f'{column_name}_{i}' for i in range(num_dims)]\n",
    "    embedd_df.columns = new_names\n",
    "    df = pd.concat([main_df, embedd_df], axis = 1)\n",
    "    print(f\"Finish concatenate: with dataframe {len(main_df)} and list {len(embedd_df)}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9fa6fe6-aac3-47f0-b779-75d4d0faf5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████| 11479/11479 [03:53<00:00, 49.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded.\n",
      "Encoding texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████| 11479/11479 [06:39<00:00, 28.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded.\n",
      "Finish concatenate: with dataframe 367304 and list 367304\n"
     ]
    }
   ],
   "source": [
    "train_review_embeddings = embedd_to_vector(train_df['review_text'])\n",
    "train_synopsis_embeddings = embedd_to_vector(train_df['plot_synopsis'])\n",
    "\n",
    "train_df = concat_to_df(train_df, train_review_embeddings, \"dim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1348efcc-1ce0-4398-a8af-01c5330af594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████| 2870/2870 [00:57<00:00, 49.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded.\n",
      "Encoding texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████| 2870/2870 [01:42<00:00, 27.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded.\n",
      "Finish concatenate: with dataframe 91826 and list 91826\n"
     ]
    }
   ],
   "source": [
    "valid_review_embeddings = embedd_to_vector(valid_df['review_text'])\n",
    "valid_synopsis_embeddings = embedd_to_vector(valid_df['plot_synopsis'])\n",
    "\n",
    "valid_df = concat_to_df(valid_df, valid_review_embeddings, \"dim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "928daeac-81f7-4746-b548-2d1742854d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████| 3587/3587 [01:11<00:00, 49.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded.\n",
      "Encoding texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████| 3587/3587 [02:03<00:00, 28.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded.\n",
      "Finish concatenate: with dataframe 114783 and list 114783\n"
     ]
    }
   ],
   "source": [
    "test_review_embeddings = embedd_to_vector(test_df['review_text'])\n",
    "test_synopsis_embeddings = embedd_to_vector(test_df['plot_synopsis'])\n",
    "\n",
    "test_df = concat_to_df(test_df, test_review_embeddings, \"dim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57637316-08c0-4aae-be02-cbe47d18728d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating similarities for training set...\n",
      "Calculating similarities for validation set...\n",
      "Calculating similarities for testing set...\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating similarities for training set...\")\n",
    "sim_scores_train = util.pairwise_cos_sim(train_review_embeddings, train_synopsis_embeddings)\n",
    "train_df['sim_score_synopsis_review'] = sim_scores_train.flatten()\n",
    "\n",
    "print(\"Calculating similarities for validation set...\")\n",
    "sim_scores_valid = util.pairwise_cos_sim(valid_review_embeddings, valid_synopsis_embeddings)\n",
    "valid_df['sim_score_synopsis_review'] = sim_scores_valid.flatten()\n",
    "\n",
    "print(\"Calculating similarities for testing set...\")\n",
    "sim_scores_test = util.pairwise_cos_sim(test_review_embeddings, test_synopsis_embeddings)\n",
    "test_df['sim_score_synopsis_review'] = sim_scores_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81f566b9-f1cf-4bc4-8262-29994c6de991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-gram\n",
    "with open(\"/SFS/project/ry/dp_sgteam/catherine/ada/dataset/ngram_vocab_list.json\", \"r\") as f:\n",
    "    ngram_vocab_list = json.load(f)\n",
    "\n",
    "ngram_to_idx = {ngram: idx for idx, ngram in enumerate(ngram_vocab_list)}\n",
    "vocab_size = len(ngram_vocab_list)\n",
    "\n",
    "def build_token_set(text):\n",
    "    tokens = re.findall(r\"[A-Za-z]+\", text.lower())\n",
    "    return tokens\n",
    "\n",
    "def ngram_vector_for_text(text, ngram_to_idx, vocab_size):\n",
    "    tokens = build_token_set(text)\n",
    "    token_set = set(tokens)\n",
    "    bigram_set = set(\" \".join(pair) for pair in zip(tokens, tokens[1:]))\n",
    "\n",
    "    vec = [0] * vocab_size\n",
    "    for ng, idx in ngram_to_idx.items():\n",
    "        if \" \" in ng:\n",
    "            if ng in bigram_set:\n",
    "                vec[idx] = 1\n",
    "        else: \n",
    "            if ng in token_set:\n",
    "                vec[idx] = 1\n",
    "    return vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d2b0f5e-097e-4778-9be2-6562f9594bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish concatenate: with dataframe 367304 and list 367304\n",
      "Finish concatenate: with dataframe 91826 and list 91826\n",
      "Finish concatenate: with dataframe 114783 and list 114783\n"
     ]
    }
   ],
   "source": [
    "train_ngram_df = pd.DataFrame([ngram_vector_for_text(t, ngram_to_idx, vocab_size) for t in train_df['review_text']])\n",
    "train_df = concat_to_df(train_df, train_ngram_df, \"ngram\")\n",
    "\n",
    "valid_ngram_df = pd.DataFrame([ngram_vector_for_text(t, ngram_to_idx, vocab_size) for t in valid_df['review_text']])\n",
    "valid_df = concat_to_df(valid_df, valid_ngram_df, \"ngram\")\n",
    "\n",
    "test_ngram_df = pd.DataFrame([ngram_vector_for_text(t, ngram_to_idx, vocab_size) for t in test_df['review_text']])\n",
    "valid_df = concat_to_df(test_df, test_ngram_df, \"ngram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63f78646-3113-411c-919c-7d1e74974d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.1.1-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /home/kangcat/miniconda3/envs/documentation/lib/python3.11/site-packages (from xgboost) (1.26.4)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost)\n",
      "  Downloading nvidia_nccl_cu12-2.28.7-py3-none-manylinux_2_18_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: scipy in /home/kangcat/miniconda3/envs/documentation/lib/python3.11/site-packages (from xgboost) (1.16.2)\n",
      "Downloading xgboost-3.1.1-py3-none-manylinux_2_28_x86_64.whl (115.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.28.7-py3-none-manylinux_2_18_x86_64.whl (296.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.8/296.8 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [xgboost]m1/2\u001b[0m [xgboost]\n",
      "\u001b[1A\u001b[2KSuccessfully installed nvidia-nccl-cu12-2.28.7 xgboost-3.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f882c8c-ef3f-47ce-b817-34b44a6c3e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_json(\"/SFS/project/ry/dp_sgteam/catherine/ada/dataset/train_data.json\",  orient=\"records\", indent=4)\n",
    "valid_df.to_json(\"/SFS/project/ry/dp_sgteam/catherine/ada/dataset/valid_data.json\",  orient=\"records\", indent=4)\n",
    "test_df.to_json(\"/SFS/project/ry/dp_sgteam/catherine/ada/dataset/test_data.json\",  orient=\"records\", indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37e4375-8785-4769-a505-ba9a42ba5029",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07168199-7a67-4f91-a7ff-dfaf995d257c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch CUDA 11.8)",
   "language": "python",
   "name": "documentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
