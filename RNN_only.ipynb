{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d53fe64-907d-472e-9c9a-1cb55a6b51cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e084218-120c-4f98-b097-6ca4c33d4112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0181501-6c99-4a1c-9974-0b9da46d56c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (573913, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_date</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_spoiler</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 February 2006</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur1898687</td>\n",
       "      <td>1</td>\n",
       "      <td>oscar year shawshank redemption write direct f...</td>\n",
       "      <td>10</td>\n",
       "      <td>A classic piece of unforgettable film-making.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6 September 2000</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur0842118</td>\n",
       "      <td>1</td>\n",
       "      <td>shawshank redemption without doubt one brillia...</td>\n",
       "      <td>10</td>\n",
       "      <td>Simply amazing. The best film of the 90's.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 August 2001</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur1285640</td>\n",
       "      <td>1</td>\n",
       "      <td>believe film best story ever tell film tell ti...</td>\n",
       "      <td>8</td>\n",
       "      <td>The best story ever told on film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 September 2002</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur1003471</td>\n",
       "      <td>1</td>\n",
       "      <td>yes spoiler film emotional impact find hard wr...</td>\n",
       "      <td>10</td>\n",
       "      <td>Busy dying or busy living?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20 May 2004</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur0226855</td>\n",
       "      <td>1</td>\n",
       "      <td>heart extraordinary movie brilliant indelible ...</td>\n",
       "      <td>8</td>\n",
       "      <td>Great story, wondrously told and acted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        review_date   movie_id    user_id  is_spoiler  \\\n",
       "0  10 February 2006  tt0111161  ur1898687           1   \n",
       "1  6 September 2000  tt0111161  ur0842118           1   \n",
       "2     3 August 2001  tt0111161  ur1285640           1   \n",
       "3  1 September 2002  tt0111161  ur1003471           1   \n",
       "4       20 May 2004  tt0111161  ur0226855           1   \n",
       "\n",
       "                                         review_text  rating  \\\n",
       "0  oscar year shawshank redemption write direct f...      10   \n",
       "1  shawshank redemption without doubt one brillia...      10   \n",
       "2  believe film best story ever tell film tell ti...       8   \n",
       "3  yes spoiler film emotional impact find hard wr...      10   \n",
       "4  heart extraordinary movie brilliant indelible ...       8   \n",
       "\n",
       "                                  review_summary  \n",
       "0  A classic piece of unforgettable film-making.  \n",
       "1     Simply amazing. The best film of the 90's.  \n",
       "2               The best story ever told on film  \n",
       "3                     Busy dying or busy living?  \n",
       "4         Great story, wondrously told and acted  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews = pd.read_json('/SFS/project/ry/dp_sgteam/catherine/ada/dataset/cleaned_data.json')\n",
    "\n",
    "print(f\"Dataset shape: {df_reviews.shape}\")\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d31562c-b8e3-415a-9103-7f84ce324b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews.dropna(subset=['review_text', 'is_spoiler'], inplace=True)\n",
    "\n",
    "X = df_reviews[['review_text']]\n",
    "y = df_reviews['is_spoiler'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8fa4751-a566-4c77-888e-891f62fec994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 459130\n",
      "Testing set size: 114783\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Testing set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cf4a364-6233-42b5-80f6-12670393b056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Weight: 2.8\n"
     ]
    }
   ],
   "source": [
    "n = y_train.value_counts()\n",
    "pos_weight = round(n[0]/n[1],2)\n",
    "pos_weight = torch.tensor(pos_weight, dtype=torch.float64)\n",
    "\n",
    "print(f\"Positive Weight: {pos_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a5c70d9-678c-48dc-a0c2-e09cb57c3dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 231082\n"
     ]
    }
   ],
   "source": [
    "# --- Build Vocabulary ---\n",
    "def build_vocab(texts, min_freq=2):\n",
    "    word_counts = Counter()\n",
    "    for text in texts:\n",
    "        word_counts.update(text.split())\n",
    "    \n",
    "    # Create a vocabulary with special tokens\n",
    "    # <pad>: for padding short sentences\n",
    "    # <unk>: for unknown words not in the vocabulary\n",
    "    vocab = {'<pad>': 0, '<unk>': 1}\n",
    "    for word, count in word_counts.items():\n",
    "        if count >= min_freq:\n",
    "            vocab[word] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "# Build vocab only on the training data\n",
    "vocab = build_vocab(X_train.review_text, min_freq=1)\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00e94e50-052f-43d8-b2e9-dca6a660175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpoilerDataset(Dataset):\n",
    "    def __init__(self, X, y, vocab):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.X.iloc[idx]\n",
    "        label = self.y.iloc[idx]\n",
    "        \n",
    "        token_ids = [self.vocab.get(word, self.vocab['<unk>']) for word in text.split()] \n",
    "        \n",
    "        return torch.tensor(token_ids, dtype=torch.long), torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "train_dataset = SpoilerDataset(X_train.review_text, y_train, vocab)\n",
    "test_dataset = SpoilerDataset(X_test.review_text, y_test, vocab)\n",
    "\n",
    "# This custom collate function handles padding within each batch.\n",
    "def collate_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    \n",
    "    padded_texts = pad_sequence(texts, batch_first=True, padding_value=vocab['<pad>'])\n",
    "    labels = torch.stack(labels)\n",
    "    \n",
    "    return padded_texts, labels\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fa118c8-7ff7-4fbb-a55e-b9274b581709",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpoilerRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=n_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if n_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim) # *2 because it's bidirectional\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "    def forward(self, text):\n",
    "        # text: [B, T]\n",
    "        embedded = self.dropout(self.embedding(text))  # [B, T, E]\n",
    "        output, _ = self.lstm(embedded)                # [B, T, 2H]\n",
    "\n",
    "        # Mask out padding positions\n",
    "        mask = (text != self.pad_idx).unsqueeze(-1)    # [B, T, 1]\n",
    "        # Use max pooling over time with -inf for pads\n",
    "        output_masked = output.masked_fill(~mask, float('-inf'))\n",
    "        pooled, _ = torch.max(output_masked, dim=1)    # [B, 2H]\n",
    "        pooled = self.dropout(pooled)\n",
    "        logits = self.fc(pooled)                       # [B, 1]\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "280f0cdc-b25d-46c6-8754-aa2bc28e8689",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocab)\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.3\n",
    "LR = 0.01\n",
    "WEIGHT_DECAY = 1e-5\n",
    "GRAD_CLIP = 1.0\n",
    "PAD_IDX = vocab['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5c6799a-dc02-454c-88f7-2806ca83b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpoilerRNN(\n",
    "    VOCAB_SIZE,\n",
    "    EMBEDDING_DIM,\n",
    "    HIDDEN_DIM,\n",
    "    OUTPUT_DIM,\n",
    "    N_LAYERS,\n",
    "    BIDIRECTIONAL,\n",
    "    DROPOUT,\n",
    "    PAD_IDX\n",
    "    ).to(device)\n",
    "\n",
    "pos_weight = pos_weight.to(device)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight = pos_weight).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR, weight_decay = WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93434f0c-bcf8-405b-b8d2-5c764a1ffdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    print(\"Training...\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for eposh in range(10):\n",
    "        epoch_loss = 0\n",
    "        for texts, labels in tqdm(train_loader):\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(texts).squeeze(1)\n",
    "            loss = criterion(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return (f\"Epoch {epoch}, Loss: {epoch_loss / len(train_loader)}\")\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for texts, labels in tqdm(loader):\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "            \n",
    "            predictions = model(texts).squeeze(1)\n",
    "            loss = criterion(predictions, labels)\n",
    "         \n",
    "            preds = torch.round(torch.sigmoid(predictions))\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "    report = classification_report(all_labels, all_preds, target_names=['Not Spoiler', 'Spoiler'], zero_division=0)\n",
    "    return epoch_loss / len(loader), report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ee96fb5-a0ac-4bca-a921-6597348b5f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████████████████████████           | 94510/114783 [48:29<08:41, 38.86it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 79%|█████████████████████████████████████████████████             | 90867/114783 [38:30<10:12, 39.04it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████| 114783/114783 [48:50<00:00, 39.17it/s]\n",
      "  7%|████▏                                                          | 7738/114783 [03:16<47:43, 37.39it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)\n",
    "    valid_loss, report = evaluate(model, test_loader, criterion)\n",
    "    \n",
    "    tqdm.write(f\"Epoch: {epoch+1:02}\")\n",
    "    tqdm.write(f\"\\tTrain Loss: {train_loss:.3f}\")\n",
    "    tqdm.write(f\"\\tVal. Loss: {valid_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98d87c62-8f76-4020-b6ec-ca22c57adf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Not Spoiler       0.85      0.78      0.82     84598\n",
      "     Spoiler       0.51      0.62      0.56     30185\n",
      "\n",
      "    accuracy                           0.74    114783\n",
      "   macro avg       0.68      0.70      0.69    114783\n",
      "weighted avg       0.76      0.74      0.75    114783\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad88ef-b680-4a14-a8dc-1f8961aa71d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# IGNORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "901d4412-c25a-4431-974a-811022f3cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the validation set on a single GPU.\n",
    "    This function should only be called by the rank 0 process.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad(): # No need to calculate gradients during evaluation\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Move to CPU and convert to numpy/list for scikit-learn\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    \n",
    "    print(f\"\\n--- Validation Results ---\")\n",
    "    print(f\"Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    report = classification_report(all_labels, all_predictions, target_names=class_names)\n",
    "    print(report)\n",
    "    \n",
    "    print(f\"--------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02c4cbaa-7a2d-409d-960c-0d01804c4bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(rank, world_size):\n",
    "    print(f\"Running DDP on rank {rank}.\")\n",
    "    setup(rank, world_size)\n",
    "    \n",
    "    epochs = 5\n",
    "    batch_size = 4\n",
    "\n",
    "    train_sampler = DistributedSampler(train_dataset, num_replicas=world_size, rank=rank, shuffle=True)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "\n",
    "    if rank == 0:\n",
    "        val_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = SpoilerRNN(\n",
    "        VOCAB_SIZE,\n",
    "        EMBEDDING_DIM,\n",
    "        HIDDEN_DIM,\n",
    "        OUTPUT_DIM,\n",
    "        N_LAYERS,\n",
    "        BIDIRECTIONAL,\n",
    "        DROPOUT,\n",
    "        PAD_IDX\n",
    "        ).to(rank)\n",
    "    \n",
    "    ddp_model = DDP(model, device_ids=[rank])\n",
    "\n",
    "    pos_weight = pos_weight.to(rank)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight = pos_weight).to(rank)\n",
    "    optimizer = optim.SGD(ddp_model.parameters(), lr=0.01)\n",
    "\n",
    "    for texts, labels in tqdm(train_loader):\n",
    "        texts, labels = texts.to(rank), labels.to(rank)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = ddp_model(texts).squeeze(1)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_loss += loss.item()\n",
    "                \n",
    "    for epoch in range(epochs):\n",
    "        train_sampler.set_epoch(epoch)\n",
    "        ddp_model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            inputs = inputs.to(rank)\n",
    "            labels = labels.to(rank)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = ddp_model(inputs).squeeze(1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "        if rank == 0:\n",
    "            avg_epoch_loss = running_loss / len(train_loader)\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "        if rank == 0:\n",
    "            evaluate(ddp_model.module, val_loader, criterion, rank)\n",
    "\n",
    "        dist.barrier()\n",
    "\n",
    "    cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93ccf2ce-eb15-4399-885d-d16d95efc756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09f3fbd2-8985-4bb9-ad19-9b2a8b7a3dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/kangcat/miniconda3/envs/documentation/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/kangcat/miniconda3/envs/documentation/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'main' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/kangcat/miniconda3/envs/documentation/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/kangcat/miniconda3/envs/documentation/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'main' on <module '__main__' (built-in)>\n",
      "W1117 01:14:17.258000 1141971 site-packages/torch/multiprocessing/spawn.py:160] Terminating process 1312088 via signal SIGTERM\n"
     ]
    },
    {
     "ename": "ProcessExitedException",
     "evalue": "process 1 terminated with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mProcessExitedException\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m      2\u001b[39m     world_size = torch.cuda.device_count() \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mmp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/documentation/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:328\u001b[39m, in \u001b[36mspawn\u001b[39m\u001b[34m(fn, args, nprocs, join, daemon, start_method)\u001b[39m\n\u001b[32m    322\u001b[39m     msg = (\n\u001b[32m    323\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis method only supports start_method=spawn (got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo use a different start_method use:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    325\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    326\u001b[39m     )\n\u001b[32m    327\u001b[39m     warnings.warn(msg, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mspawn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/documentation/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:284\u001b[39m, in \u001b[36mstart_processes\u001b[39m\u001b[34m(fn, args, nprocs, join, daemon, start_method)\u001b[39m\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[32m    283\u001b[39m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/documentation/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:192\u001b[39m, in \u001b[36mProcessContext.join\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    184\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[32m    185\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m terminated with signal \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % (error_index, name),\n\u001b[32m    186\u001b[39m             error_index=error_index,\n\u001b[32m   (...)\u001b[39m\u001b[32m    189\u001b[39m             signal_name=name,\n\u001b[32m    190\u001b[39m         )\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[32m    193\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m terminated with exit code \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m % (error_index, exitcode),\n\u001b[32m    194\u001b[39m             error_index=error_index,\n\u001b[32m    195\u001b[39m             error_pid=failed_process.pid,\n\u001b[32m    196\u001b[39m             exit_code=exitcode,\n\u001b[32m    197\u001b[39m         )\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m.error_files[error_index], \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[32m    200\u001b[39m     original_trace = pickle.load(fh)\n",
      "\u001b[31mProcessExitedException\u001b[39m: process 1 terminated with exit code 1"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    world_size = torch.cuda.device_count() or 1\n",
    "    mp.spawn(\n",
    "        main,\n",
    "        args=(world_size,),\n",
    "        nprocs=world_size,\n",
    "        join=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a1e664-25c5-46be-8cc4-4baa398d9bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "print(\"Training..\")\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)\n",
    "    valid_loss, report = evaluate(model, valid_loader, criterion)\n",
    "\n",
    "    print(f'Rank:{rank}')\n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289986dd-433a-4c57-bb80-3c03438412fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, final_report = evaluate(model, test_loader, criterion)\n",
    "print(final_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3beed2-99e9-4374-a622-4f601c775df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb39695-c2a8-415f-9314-83e3e2804b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c9ed07-f0fc-4d26-a9ca-1ea4e04d82f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33caed15-1d25-43ce-a370-5c239fbef785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    print(\"Training...\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for eposh in range(10):\n",
    "        epoch_loss = 0\n",
    "        for texts, labels in tqdm(train_loader):\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(texts).squeeze(1)\n",
    "            loss = criterion(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return (f\"Epoch {epoch}, Loss: {epoch_loss / len(train_loader)}\")\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for texts, labels in tqdm(loader):\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "            \n",
    "            predictions = model(texts).squeeze(1)\n",
    "            loss = criterion(predictions, labels)\n",
    "         \n",
    "            preds = torch.round(torch.sigmoid(predictions))\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "    report = classification_report(all_labels, all_preds, target_names=['Not Spoiler', 'Spoiler'], zero_division=0)\n",
    "    return epoch_loss / len(loader), report\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch CUDA 11.8)",
   "language": "python",
   "name": "documentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
