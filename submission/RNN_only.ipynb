{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d53fe64-907d-472e-9c9a-1cb55a6b51cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad786995-37a6-458f-aa5b-6faafb7d41a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e084218-120c-4f98-b097-6ca4c33d4112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0181501-6c99-4a1c-9974-0b9da46d56c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (573913, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_date</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_spoiler</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 February 2006</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur1898687</td>\n",
       "      <td>1</td>\n",
       "      <td>oscar year shawshank redemption write direct f...</td>\n",
       "      <td>10</td>\n",
       "      <td>A classic piece of unforgettable film-making.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6 September 2000</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur0842118</td>\n",
       "      <td>1</td>\n",
       "      <td>shawshank redemption without doubt one brillia...</td>\n",
       "      <td>10</td>\n",
       "      <td>Simply amazing. The best film of the 90's.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 August 2001</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur1285640</td>\n",
       "      <td>1</td>\n",
       "      <td>believe film best story ever tell film tell ti...</td>\n",
       "      <td>8</td>\n",
       "      <td>The best story ever told on film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 September 2002</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur1003471</td>\n",
       "      <td>1</td>\n",
       "      <td>yes spoiler film emotional impact find hard wr...</td>\n",
       "      <td>10</td>\n",
       "      <td>Busy dying or busy living?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20 May 2004</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>ur0226855</td>\n",
       "      <td>1</td>\n",
       "      <td>heart extraordinary movie brilliant indelible ...</td>\n",
       "      <td>8</td>\n",
       "      <td>Great story, wondrously told and acted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        review_date   movie_id    user_id  is_spoiler  \\\n",
       "0  10 February 2006  tt0111161  ur1898687           1   \n",
       "1  6 September 2000  tt0111161  ur0842118           1   \n",
       "2     3 August 2001  tt0111161  ur1285640           1   \n",
       "3  1 September 2002  tt0111161  ur1003471           1   \n",
       "4       20 May 2004  tt0111161  ur0226855           1   \n",
       "\n",
       "                                         review_text  rating  \\\n",
       "0  oscar year shawshank redemption write direct f...      10   \n",
       "1  shawshank redemption without doubt one brillia...      10   \n",
       "2  believe film best story ever tell film tell ti...       8   \n",
       "3  yes spoiler film emotional impact find hard wr...      10   \n",
       "4  heart extraordinary movie brilliant indelible ...       8   \n",
       "\n",
       "                                  review_summary  \n",
       "0  A classic piece of unforgettable film-making.  \n",
       "1     Simply amazing. The best film of the 90's.  \n",
       "2               The best story ever told on film  \n",
       "3                     Busy dying or busy living?  \n",
       "4         Great story, wondrously told and acted  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = os.environ['DIR_PATH']\n",
    "df_reviews = pd.read_json(f'{dir_path}/dataset/cleaned_data.json')\n",
    "\n",
    "print(f\"Dataset shape: {df_reviews.shape}\")\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d31562c-b8e3-415a-9103-7f84ce324b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews.dropna(subset=['review_text', 'is_spoiler'], inplace=True)\n",
    "\n",
    "X = df_reviews[['review_text']]\n",
    "y = df_reviews['is_spoiler'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8fa4751-a566-4c77-888e-891f62fec994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 459130\n",
      "Testing set size: 114783\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Testing set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cf4a364-6233-42b5-80f6-12670393b056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Weight: 2.8\n"
     ]
    }
   ],
   "source": [
    "n = y_train.value_counts()\n",
    "pos_weight = round(n[0]/n[1],2)\n",
    "pos_weight = torch.tensor(pos_weight, dtype=torch.float64)\n",
    "\n",
    "print(f\"Positive Weight: {pos_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a5c70d9-678c-48dc-a0c2-e09cb57c3dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 231082\n"
     ]
    }
   ],
   "source": [
    "# --- Build Vocabulary ---\n",
    "def build_vocab(texts, min_freq=2):\n",
    "    word_counts = Counter()\n",
    "    for text in texts:\n",
    "        word_counts.update(text.split())\n",
    "    \n",
    "    # Create a vocabulary with special tokens\n",
    "    # <pad>: for padding short sentences\n",
    "    # <unk>: for unknown words not in the vocabulary\n",
    "    vocab = {'<pad>': 0, '<unk>': 1}\n",
    "    for word, count in word_counts.items():\n",
    "        if count >= min_freq:\n",
    "            vocab[word] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "# Build vocab only on the training data\n",
    "vocab = build_vocab(X_train.review_text, min_freq=1)\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00e94e50-052f-43d8-b2e9-dca6a660175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpoilerDataset(Dataset):\n",
    "    def __init__(self, X, y, vocab):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.X.iloc[idx]\n",
    "        label = self.y.iloc[idx]\n",
    "        \n",
    "        token_ids = [self.vocab.get(word, self.vocab['<unk>']) for word in text.split()] \n",
    "        \n",
    "        return torch.tensor(token_ids, dtype=torch.long), torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "train_dataset = SpoilerDataset(X_train.review_text, y_train, vocab)\n",
    "test_dataset = SpoilerDataset(X_test.review_text, y_test, vocab)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    \n",
    "    padded_texts = pad_sequence(texts, batch_first=True, padding_value=vocab['<pad>'])\n",
    "    labels = torch.stack(labels)\n",
    "    \n",
    "    return padded_texts, labels\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fa118c8-7ff7-4fbb-a55e-b9274b581709",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpoilerRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=n_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if n_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "    def forward(self, text):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        output, _ = self.lstm(embedded)           \n",
    "\n",
    "        mask = (text != self.pad_idx).unsqueeze(-1)\n",
    "\n",
    "        output_masked = output.masked_fill(~mask, float('-inf'))\n",
    "        pooled, _ = torch.max(output_masked, dim=1) \n",
    "        pooled = self.dropout(pooled)\n",
    "        logits = self.fc(pooled)                    \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "280f0cdc-b25d-46c6-8754-aa2bc28e8689",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocab)\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.3\n",
    "LR = 0.01\n",
    "WEIGHT_DECAY = 1e-5\n",
    "GRAD_CLIP = 1.0\n",
    "PAD_IDX = vocab['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5c6799a-dc02-454c-88f7-2806ca83b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpoilerRNN(\n",
    "    VOCAB_SIZE,\n",
    "    EMBEDDING_DIM,\n",
    "    HIDDEN_DIM,\n",
    "    OUTPUT_DIM,\n",
    "    N_LAYERS,\n",
    "    BIDIRECTIONAL,\n",
    "    DROPOUT,\n",
    "    PAD_IDX\n",
    "    ).to(device)\n",
    "\n",
    "pos_weight = pos_weight.to(device)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight = pos_weight).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR, weight_decay = WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93434f0c-bcf8-405b-b8d2-5c764a1ffdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    print(\"Training...\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for eposh in range(10):\n",
    "        epoch_loss = 0\n",
    "        for texts, labels in tqdm(train_loader):\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(texts).squeeze(1)\n",
    "            loss = criterion(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return (f\"Epoch {epoch}, Loss: {epoch_loss / len(train_loader)}\")\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for texts, labels in tqdm(loader):\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "            \n",
    "            predictions = model(texts).squeeze(1)\n",
    "            loss = criterion(predictions, labels)\n",
    "         \n",
    "            preds = torch.round(torch.sigmoid(predictions))\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "    report = classification_report(all_labels, all_preds, target_names=['Not Spoiler', 'Spoiler'], zero_division=0)\n",
    "    return epoch_loss / len(loader), report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ee96fb5-a0ac-4bca-a921-6597348b5f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████████████████████████           | 94510/114783 [48:29<08:41, 38.86it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 79%|█████████████████████████████████████████████████             | 90867/114783 [38:30<10:12, 39.04it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████| 114783/114783 [48:50<00:00, 39.17it/s]\n",
      "  7%|████▏                                                          | 7738/114783 [03:16<47:43, 37.39it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)\n",
    "    valid_loss, report = evaluate(model, test_loader, criterion)\n",
    "    \n",
    "    tqdm.write(f\"Epoch: {epoch+1:02}\")\n",
    "    tqdm.write(f\"\\tTrain Loss: {train_loss:.3f}\")\n",
    "    tqdm.write(f\"\\tVal. Loss: {valid_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98d87c62-8f76-4020-b6ec-ca22c57adf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Not Spoiler       0.85      0.78      0.82     84598\n",
      "     Spoiler       0.51      0.62      0.56     30185\n",
      "\n",
      "    accuracy                           0.74    114783\n",
      "   macro avg       0.68      0.70      0.69    114783\n",
      "weighted avg       0.76      0.74      0.75    114783\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch CUDA 11.8)",
   "language": "python",
   "name": "documentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
